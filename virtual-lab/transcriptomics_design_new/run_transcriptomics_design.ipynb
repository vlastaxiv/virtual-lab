{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import concurrent.futures\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from virtual_lab.constants import CONSISTENT_TEMPERATURE, CREATIVE_TEMPERATURE\n",
    "from virtual_lab.prompts import (\n",
    "    CODING_RULES,\n",
    "    REWRITE_PROMPT,\n",
    "    create_merge_prompt\n",
    ")\n",
    "from virtual_lab.run_meeting import run_meeting\n",
    "from virtual_lab.utils import load_summaries\n",
    "\n",
    "from transcriptomics_constants import (\n",
    "    background_prompt,\n",
    "    experimental_results_prompt,\n",
    "    num_iterations,\n",
    "    num_rounds,\n",
    "    discussions_phase_to_dir,\n",
    "    principal_investigator,\n",
    "    team_members,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9259ddc2710488f",
   "metadata": {},
   "source": [
    "## Team selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f47749ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team selection - prompts, pozor, kdy≈æ si jednou vyberu t√Ωm, u≈æ to znova nespou≈°t√≠m a nech√°m si ty konverzace v diskuzi\n",
    "team_selection_agenda = f\"\"\"\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt}\n",
    "\n",
    "You need to select a team of four scientists to help you with this transcriptomics project. The team should deal with these analytical challenges:\n",
    "\n",
    "- Multi-factorial statistical modeling to separate resistance from confounding factors\n",
    "- RNA-seq analysis and differential expression (DESeq2, edgeR)\n",
    "- Biological interpretation in the context of Giardia intestinalis biology and protozoan drug resistance\n",
    "- Implementation and development of automated, reproducible pipelines (R/Bioconductor, Python)\n",
    "- Functional annotation and characterization of putative/hypothetical proteins\n",
    "\n",
    "NOTE: Giardia intestinalis is a unique protozoan parasite with unusual biology. Understanding gene expression changes requires expertise in parasite physiology and drug resistance mechanisms.\n",
    "\n",
    "IMPORTANT: Many Giardia genes are annotated as \"putative protein\" or \"hypothetical protein\". The team needs expertise in:\n",
    "- Protein function prediction (sequence homology, domain analysis, structural prediction)\n",
    "- Comparative genomics to infer function from related organisms\n",
    "- Literature mining and database searches to assign putative functions\n",
    "\n",
    "The team should also include a software-oriented member capable of automating the analysis, maintaining reproducible workflows, and integrating code across R and Python environments.\n",
    "The selected scientists should complement each others expertise and collaborate as an integrated research team.\n",
    "\n",
    "Please select the team members in the following format. You should NOT include yourself (Principal Investigator) in the list. Write the team as a Python list of Agent objects with \"model=model\" as the last parameter.\n",
    "\n",
    "Agent(\n",
    "    title=\"Principal Investigator\",\n",
    "    expertise=\"transcriptomics, RNA-seq analysis, microbial drug resistance, experimental design\",\n",
    "    goal=\"identify molecular mechanisms of metronidazole resistance in Giardia intestinalis\",\n",
    "    role=\"lead a team of experts to properly re-analyze the RNA-seq data and identify validated candidate resistance genes\",\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "Principal Investigator, please provide your response.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50722e4dadc135d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rounds (+ Final Round):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team:   0%|          | 0/2 [00:10<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 1,175\n",
      "Output token count: 413\n",
      "Tool token count: 0\n",
      "Max token length: 1,588\n",
      "Cost: $0.01\n",
      "Time: 0:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:12<?, ?it/s]\n",
      "\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 1,175\n",
      "Output token count: 446\n",
      "Tool token count: 0\n",
      "Max token length: 1,621\n",
      "Cost: $0.01\n",
      "Time: 0:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:13<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 1,175\n",
      "Output token count: 708\n",
      "Tool token count: 0\n",
      "Max token length: 1,883\n",
      "Cost: $0.01\n",
      "Time: 0:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:15<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 1,175\n",
      "Output token count: 483\n",
      "Tool token count: 0\n",
      "Max token length: 1,658\n",
      "Cost: $0.01\n",
      "Time: 0:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:15<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 1,175\n",
      "Output token count: 476\n",
      "Tool token count: 0\n",
      "Max token length: 1,651\n",
      "Cost: $0.01\n",
      "Time: 0:18\n"
     ]
    }
   ],
   "source": [
    "# Team selection - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=principal_investigator,\n",
    "            agenda=team_selection_agenda,\n",
    "            save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c023cebeaaf883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:31<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:31<00:00, 31.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 3,851\n",
      "Output token count: 924\n",
      "Tool token count: 0\n",
      "Max token length: 4,775\n",
      "Cost: $0.02\n",
      "Time: 0:33\n"
     ]
    }
   ],
   "source": [
    "# Team selection - merge\n",
    "team_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"team_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(team_selection_summaries)}\")\n",
    "\n",
    "team_selection_merge_prompt = create_merge_prompt(agenda=team_selection_agenda)\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=team_selection_summaries,\n",
    "    agenda=team_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804141d0b26537",
   "metadata": {},
   "source": [
    "## Projects specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df84a9e45d31bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_specification_agenda = f\"\"\"\n",
    "\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt} \n",
    "Design a transcriptomic analysis plan to identify genes specifically linked to metronidazole resistance in the BER line of Giardia intestinalis. Clearly distinguish resistance-specific effects from general drug responses and baseline strain differences. Propose a statistical model (e.g. with interaction terms) to detect these effects. Prioritize candidate resistance genes for validation and link them to biological functions using functional annotation tools. Include an approach for analyzing uncharacterized (putative) proteins.\"\"\"\n",
    "\n",
    "project_specification_questions = (\n",
    "    \"What is the most effective approach to identify genes linked to metronidazole resistance in *Giardia intestinalis*?\",\n",
    "    \"How can resistance-specific expression be separated from general drug response and baseline differences between strains?\",\n",
    "    \"Is a simple comparison sufficient, or is a complex statistical model needed? Why?\",\n",
    "    \"How should candidate genes be functionally annotated and connected to biological pathways?\",\n",
    "    \"What strategy can identify and characterize putative (unannotated) proteins among the candidate genes?\",\n",
    "    \"Are any additional files, metadata, or annotations needed to perform the analysis effectively?\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3430b206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ Spou≈°t√≠m diskuzi 1/5...\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [02:42<00:00, 32.54s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:32<00:00, 18.52s/it]<08:08, 162.72s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:53<00:00, 22.68s/it]<04:02, 121.49s/it]\n",
      "Team:   0%|          | 0/5 [00:25<?, ?it/s]4 [06:08<01:57, 117.80s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [06:34<00:00, 98.63s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 75,320\n",
      "Output token count: 6,773\n",
      "Tool token count: 0\n",
      "Max token length: 10,037\n",
      "Cost: $0.26\n",
      "Time: 6:39\n",
      "\n",
      "‚úÖ Diskuze 1 dokonƒçena!\n",
      "\n",
      "\n",
      "============================================================\n",
      "üöÄ Spou≈°t√≠m diskuzi 2/5...\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:07<00:00, 13.58s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:29<00:00, 17.98s/it]<03:23, 67.88s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:42<00:00, 20.53s/it]<02:41, 80.84s/it]\n",
      "Team:   0%|          | 0/5 [00:27<?, ?it/s]4 [04:20<01:30, 90.79s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [04:47<00:00, 71.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 76,093\n",
      "Output token count: 7,082\n",
      "Tool token count: 0\n",
      "Max token length: 10,346\n",
      "Cost: $0.26\n",
      "Time: 4:54\n",
      "\n",
      "‚úÖ Diskuze 2 dokonƒçena!\n",
      "\n",
      "\n",
      "============================================================\n",
      "üöÄ Spou≈°t√≠m diskuzi 3/5...\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [02:00<00:00, 24.15s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:36<00:00, 19.26s/it]<06:02, 120.73s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:37<00:00, 19.42s/it]<03:32, 106.35s/it]\n",
      "Team:   0%|          | 0/5 [00:42<?, ?it/s]4 [05:14<01:42, 102.13s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [05:57<00:00, 89.26s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 75,598\n",
      "Output token count: 6,910\n",
      "Tool token count: 0\n",
      "Max token length: 10,174\n",
      "Cost: $0.26\n",
      "Time: 6:01\n",
      "\n",
      "‚úÖ Diskuze 3 dokonƒçena!\n",
      "\n",
      "\n",
      "============================================================\n",
      "üöÄ Spou≈°t√≠m diskuzi 4/5...\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:24<00:00, 16.95s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:44<00:00, 20.99s/it]<04:14, 84.74s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:51<00:00, 22.36s/it]<03:13, 96.62s/it]\n",
      "Team:   0%|          | 0/5 [00:31<?, ?it/s]4 [05:01<01:43, 103.56s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [05:32<00:00, 83.17s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 78,545\n",
      "Output token count: 7,269\n",
      "Tool token count: 0\n",
      "Max token length: 10,533\n",
      "Cost: $0.27\n",
      "Time: 5:37\n",
      "\n",
      "‚úÖ Diskuze 4 dokonƒçena!\n",
      "\n",
      "\n",
      "============================================================\n",
      "üöÄ Spou≈°t√≠m diskuzi 5/5...\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:48<00:00, 21.69s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:38<00:00, 19.70s/it]<05:25, 108.44s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:12<00:00, 14.41s/it]<03:25, 102.60s/it]\n",
      "Team:   0%|          | 0/5 [00:48<?, ?it/s]4 [04:39<01:28, 88.66s/it] \n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [05:27<00:00, 81.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 76,391\n",
      "Output token count: 6,686\n",
      "Tool token count: 0\n",
      "Max token length: 9,950\n",
      "Cost: $0.26\n",
      "Time: 5:33\n",
      "\n",
      "‚úÖ Diskuze 5 dokonƒçena!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for iteration_num in range(num_iterations):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üöÄ Spou≈°t√≠m diskuzi {iteration_num + 1}/5...\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    run_meeting(\n",
    "        meeting_type=\"team\",\n",
    "        team_lead=principal_investigator,\n",
    "        team_members=team_members,\n",
    "        agenda=project_specification_agenda,\n",
    "        agenda_questions=project_specification_questions,\n",
    "        save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
    "        save_name=f\"discussion_{iteration_num + 1}\",\n",
    "        temperature=CREATIVE_TEMPERATURE,\n",
    "        num_rounds=num_rounds,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Diskuze {iteration_num + 1} dokonƒçena!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e66e0cfa85f2176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:45<00:00, 22.72s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:30<00:00, 15.18s/it]<02:16, 45.44s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:03<00:00, 31.56s/it]<01:13, 36.58s/it]\n",
      "Team:   0%|          | 0/2 [00:35<?, ?it/s]4 [02:18<00:48, 48.70s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [02:54<00:00, 43.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 62,103\n",
      "Output token count: 6,038\n",
      "Tool token count: 0\n",
      "Max token length: 12,618\n",
      "Cost: $0.22\n",
      "Time: 2:56\n"
     ]
    }
   ],
   "source": [
    "# Project specification - merge\n",
    "project_specification_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"project_specification\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(project_specification_summaries)}\")\n",
    "\n",
    "project_specification_merge_prompt = create_merge_prompt(\n",
    "    agenda=project_specification_agenda,\n",
    "    agenda_questions=project_specification_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=project_specification_summaries,\n",
    "    agenda=project_specification_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    num_rounds=num_rounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5307d354d28011",
   "metadata": {},
   "source": [
    "## Tools Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e17e16e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prior summaries: 1\n"
     ]
    }
   ],
   "source": [
    "# Tools selection - prompts\n",
    "tools_selection_agenda = f\"\"\"\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt}\n",
    "\n",
    "Based on the finalized project specification, identify the specific computational and bioinformatics tools required to implement the transcriptomics analysis plan in practice.\n",
    "\n",
    "Focus on selecting and justifying concrete tools, libraries, or platforms that will make the workflow executable and reproducible ‚Äî from differential expression to functional annotation and visualization.\n",
    "\n",
    "Your selection should:\n",
    "- Build directly on the statistical and analytical strategy defined in the project specification.\n",
    "- Include both established tools and recent innovations relevant to the field.\n",
    "- Consider compatibility between R and Python environments (e.g., DESeq2 + Scikit-learn integration).\n",
    "- Highlight new or improved AI-based platforms for protein structure and function prediction.\n",
    "- Reflect the specific challenges of non-model organisms like Giardia intestinalis.\n",
    "\n",
    "For each tool, please specify:\n",
    "1. How it will be used in the workflow and at which step.\n",
    "2. Why it is appropriate for this project and what makes it preferable to alternatives.\n",
    "3. Any recent or experimental tools worth exploring as complementary options.\n",
    "4. How the tool will interface with others in the pipeline to ensure automation and reproducibility.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tools_selection_questions = (\n",
    "    \"Which computational tools and libraries should be used for each stage of the RNA-seq analysis (differential expression, annotation, visualization)?\",\n",
    "    \"How will each selected tool be applied specifically to identify metronidazole resistance mechanisms?\",\n",
    "    \"Which pathway databases and annotation resources are most appropriate for Giardia intestinalis?\",\n",
    "    \"Which modern or AI-driven tools can improve the prediction and characterization of putative proteins?\",\n",
    "    \"Are there any recent tools or databases developed for protozoan genomics that could enhance this analysis?\",\n",
    ")\n",
    "\n",
    "tools_selection_prior_summaries = load_summaries(\n",
    "    discussion_paths=[discussions_phase_to_dir[\"project_specification\"] / \"merged.json\"])\n",
    "print(f\"Number of prior summaries: {len(tools_selection_prior_summaries)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a2eab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ Spou≈°t√≠m diskuzi 1/5...\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:33<00:00, 18.79s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:48<00:00, 21.74s/it]<04:41, 93.94s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [02:05<00:00, 25.10s/it]<03:25, 102.62s/it]\n",
      "Team:   0%|          | 0/5 [00:32<?, ?it/s]4 [05:28<01:53, 113.07s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [06:01<00:00, 90.28s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 102,836\n",
      "Output token count: 7,779\n",
      "Tool token count: 0\n",
      "Max token length: 12,460\n",
      "Cost: $0.33\n",
      "Time: 6:05\n",
      "\n",
      "‚úÖ Diskuze 1 dokonƒçena!\n",
      "\n",
      "\n",
      "============================================================\n",
      "üöÄ Spou≈°t√≠m diskuzi 2/5...\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:41<00:00, 20.32s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [02:00<00:00, 24.19s/it]<05:04, 101.62s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:49<00:00, 21.91s/it]<03:45, 112.99s/it]\n",
      "Team:   0%|          | 0/5 [00:44<?, ?it/s]4 [05:32<01:51, 111.43s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [06:16<00:00, 94.16s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 107,298\n",
      "Output token count: 8,105\n",
      "Tool token count: 0\n",
      "Max token length: 12,786\n",
      "Cost: $0.35\n",
      "Time: 6:22\n",
      "\n",
      "‚úÖ Diskuze 2 dokonƒçena!\n",
      "\n",
      "\n",
      "============================================================\n",
      "üöÄ Spou≈°t√≠m diskuzi 3/5...\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:59<00:00, 23.88s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:33<00:00, 18.77s/it]<05:58, 119.40s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:37<00:00, 19.44s/it]<03:28, 104.38s/it]\n",
      "Team:   0%|          | 0/5 [00:40<?, ?it/s]4 [05:10<01:41, 101.10s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [05:50<00:00, 87.75s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 99,739\n",
      "Output token count: 6,819\n",
      "Tool token count: 0\n",
      "Max token length: 11,500\n",
      "Cost: $0.32\n",
      "Time: 5:55\n",
      "\n",
      "‚úÖ Diskuze 3 dokonƒçena!\n",
      "\n",
      "\n",
      "============================================================\n",
      "üöÄ Spou≈°t√≠m diskuzi 4/5...\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:49<00:00, 21.83s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:41<00:00, 20.28s/it]<05:27, 109.17s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:47<00:00, 21.49s/it]<03:29, 104.60s/it]\n",
      "Team:   0%|          | 0/5 [00:55<?, ?it/s]4 [05:18<01:45, 105.91s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [06:13<00:00, 93.48s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 109,814\n",
      "Output token count: 8,533\n",
      "Tool token count: 0\n",
      "Max token length: 13,214\n",
      "Cost: $0.36\n",
      "Time: 6:18\n",
      "\n",
      "‚úÖ Diskuze 4 dokonƒçena!\n",
      "\n",
      "\n",
      "============================================================\n",
      "üöÄ Spou≈°t√≠m diskuzi 5/5...\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:55<00:00, 23.03s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:51<00:00, 22.39s/it]<05:45, 115.15s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:53<00:00, 22.71s/it]<03:46, 113.26s/it]\n",
      "Team:   0%|          | 0/5 [00:25<?, ?it/s]4 [05:40<01:53, 113.38s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [06:05<00:00, 91.47s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 108,758\n",
      "Output token count: 8,300\n",
      "Tool token count: 0\n",
      "Max token length: 12,981\n",
      "Cost: $0.35\n",
      "Time: 6:10\n",
      "\n",
      "‚úÖ Diskuze 5 dokonƒçena!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for iteration_num in range(num_iterations):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üöÄ Spou≈°t√≠m diskuzi {iteration_num + 1}/5...\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    run_meeting(\n",
    "        meeting_type=\"team\",\n",
    "        team_lead=principal_investigator,\n",
    "        team_members=team_members,\n",
    "        summaries=tools_selection_prior_summaries,\n",
    "        agenda=tools_selection_agenda,\n",
    "        agenda_questions=tools_selection_questions,\n",
    "        save_dir=discussions_phase_to_dir[\"tools_selection\"],\n",
    "        save_name=f\"discussion_{iteration_num + 1}\",\n",
    "        temperature=CREATIVE_TEMPERATURE,\n",
    "        num_rounds=num_rounds,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Diskuze {iteration_num + 1} dokonƒçena!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "580378a119b0cce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:36<00:00, 48.32s/it]<?, ?it/s]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:17<00:00, 38.78s/it]<04:49, 96.65s/it]\n",
      "Team: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:54<00:00, 27.02s/it]<02:50, 85.42s/it]\n",
      "Team:   0%|          | 0/2 [00:27<?, ?it/s]4 [03:48<01:11, 71.09s/it]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [04:15<00:00, 63.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 63,594\n",
      "Output token count: 6,760\n",
      "Tool token count: 0\n",
      "Max token length: 13,383\n",
      "Cost: $0.23\n",
      "Time: 4:18\n"
     ]
    }
   ],
   "source": [
    "# Tools selection - merge\n",
    "tools_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"tools_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(tools_selection_summaries)}\")\n",
    "\n",
    "tools_selection_merge_prompt = create_merge_prompt(\n",
    "    agenda=tools_selection_agenda,\n",
    "    agenda_questions=tools_selection_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=tools_selection_summaries,\n",
    "    agenda=tools_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"tools_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    num_rounds=num_rounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3777aacd05e6e17",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d28163b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prior summaries: 3\n"
     ]
    }
   ],
   "source": [
    "# Implementation agent selection - prompts\n",
    "implementation_agent_selection_agenda = f\"\"\"\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt}\n",
    "\n",
    "Based on the project specification and selected tools, your team needs to implement the transcriptomics analysis pipeline.\n",
    "\n",
    "The analysis requires implementation of 3 major components:\n",
    "\n",
    "1. Statistical Analysis & QC\n",
    "   - DESeq2 multi-factorial model\n",
    "   - edgeR validation (optional cross-check)\n",
    "   - Basic visualization (PCA, volcano plots)\n",
    "   - Output: DEG lists, QC plots\n",
    "   \n",
    "2. Functional Analysis & Networks\n",
    "   - ClusterProfiler (GO/KEGG/Reactome enrichment)\n",
    "   - WGCNA (co-expression modules)\n",
    "   - InterPro/Pfam (domain annotation)\n",
    "   - STRING (protein interactions)\n",
    "   - Candidate gene ranking\n",
    "   - Output: Enriched pathways, gene modules, network data\n",
    "   \n",
    "3. AI-driven Characterization & Visualization\n",
    "   - AlphaFold for unannotated proteins\n",
    "   - DeepGOPlus function prediction\n",
    "   - Comprehensive plots (heatmaps, networks, interactive)\n",
    "   - Final integrated report\n",
    "   - Output: Structure predictions, final figures\n",
    "\n",
    "\n",
    "For each component, please select the team member who will implement the component. A team member may implement more than one component.\n",
    "\n",
    "Consider each team member's expertise when making assignments.\n",
    "\"\"\"\n",
    "\n",
    "implementation_agent_selection_questions = (\n",
    "    \"Which team member will implement the statistical analysis pipeline (DESeq2, edgeR, QC visualization)?\",\n",
    "    \"Which team member will implement the functional and network analysis pipeline (ClusterProfiler, WGCNA, STRING, InterPro)?\",\n",
    "    \"Which team member will implement AI-driven characterization and comprehensive visualization (AlphaFold, DeepGOPlus, final plots)?\",\n",
    ")\n",
    "\n",
    "\n",
    "implementation_agent_selection_prior_summaries = load_summaries(\n",
    "    discussion_paths=[\n",
    "        discussions_phase_to_dir[\"team_selection\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"project_specification\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"tools_selection\"] / \"merged.json\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Number of prior summaries: {len(implementation_agent_selection_prior_summaries)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "958dd1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Spou≈°t√≠m implementation agent selection diskuzi 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:21<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:21<00:00, 21.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 4,762\n",
      "Output token count: 596\n",
      "Tool token count: 0\n",
      "Max token length: 5,358\n",
      "Cost: $0.02\n",
      "Time: 0:22\n",
      "‚úÖ Diskuze 1 dokonƒçena!\n",
      "üöÄ Spou≈°t√≠m implementation agent selection diskuzi 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:25<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:25<00:00, 25.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 4,762\n",
      "Output token count: 561\n",
      "Tool token count: 0\n",
      "Max token length: 5,323\n",
      "Cost: $0.02\n",
      "Time: 0:29\n",
      "‚úÖ Diskuze 2 dokonƒçena!\n",
      "üöÄ Spou≈°t√≠m implementation agent selection diskuzi 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:32<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:32<00:00, 32.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 4,762\n",
      "Output token count: 483\n",
      "Tool token count: 0\n",
      "Max token length: 5,245\n",
      "Cost: $0.02\n",
      "Time: 0:34\n",
      "‚úÖ Diskuze 3 dokonƒçena!\n",
      "üöÄ Spou≈°t√≠m implementation agent selection diskuzi 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:19<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:19<00:00, 19.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 4,762\n",
      "Output token count: 454\n",
      "Tool token count: 0\n",
      "Max token length: 5,216\n",
      "Cost: $0.02\n",
      "Time: 0:21\n",
      "‚úÖ Diskuze 4 dokonƒçena!\n",
      "üöÄ Spou≈°t√≠m implementation agent selection diskuzi 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:12<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 4,762\n",
      "Output token count: 442\n",
      "Tool token count: 0\n",
      "Max token length: 5,204\n",
      "Cost: $0.02\n",
      "Time: 0:14\n",
      "‚úÖ Diskuze 5 dokonƒçena!\n"
     ]
    }
   ],
   "source": [
    "# Implementation agent selection - discussion\n",
    "for iteration_num in range(num_iterations):\n",
    "    print(f\"üöÄ Spou≈°t√≠m implementation agent selection diskuzi {iteration_num + 1}/{num_iterations}...\")\n",
    "    run_meeting(\n",
    "        meeting_type=\"individual\",\n",
    "        team_member=principal_investigator,\n",
    "        summaries=implementation_agent_selection_prior_summaries,\n",
    "        agenda=implementation_agent_selection_agenda,\n",
    "        agenda_questions=implementation_agent_selection_questions,\n",
    "        save_dir=discussions_phase_to_dir[\"implementation_agent_selection\"],\n",
    "        save_name=f\"discussion_{iteration_num + 1}\",\n",
    "        temperature=CREATIVE_TEMPERATURE,\n",
    "    )\n",
    "    print(f\"‚úÖ Diskuze {iteration_num + 1} dokonƒçena!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b741ab035e21003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/2 [00:17<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:17<00:00, 17.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 3,810\n",
      "Output token count: 671\n",
      "Tool token count: 0\n",
      "Max token length: 4,481\n",
      "Cost: $0.02\n",
      "Time: 0:19\n"
     ]
    }
   ],
   "source": [
    "# Implementation - merge\n",
    "implementation_agent_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"implementation_agent_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(implementation_agent_selection_summaries)}\")\n",
    "\n",
    "implementation_agent_selection_merge_prompt = create_merge_prompt(\n",
    "    agenda=implementation_agent_selection_agenda,\n",
    "    agenda_questions=implementation_agent_selection_questions\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=implementation_agent_selection_summaries,\n",
    "    agenda=implementation_agent_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"implementation_agent_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0dff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting short team sanity check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Team:   0%|          | 0/5 [00:13<?, ?it/s]1 [00:00<?, ?it/s]\n",
      "Rounds (+ Final Round): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token count: 2,888\n",
      "Output token count: 246\n",
      "Tool token count: 0\n",
      "Max token length: 3,134\n",
      "Cost: $0.01\n",
      "Time: 0:19\n",
      "Team sanity check completed.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Quick team sanity check: review of task distribution\n",
    "# ============================================================\n",
    "from virtual_lab.prompts import SCIENTIFIC_CRITIC\n",
    "\n",
    "implementation_agent_selection_team_prompt = \"\"\"\n",
    "The Principal Investigator has assigned implementation tasks among the team members.\n",
    "Please discuss whether this task distribution is realistic and well-balanced.\n",
    "Focus on whether any team member might be overloaded or if the division could be simplified.\n",
    "Do not propose new methods ‚Äî only assess the practicality and balance of the current plan.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Starting short team sanity check...\")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"team\",\n",
    "    team_lead=principal_investigator,\n",
    "    team_members=team_members + (SCIENTIFIC_CRITIC,),\n",
    "    summaries=implementation_agent_selection_summaries,\n",
    "    agenda=implementation_agent_selection_team_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"implementation_agent_selection\"],\n",
    "    save_name=\"team_sanity_check\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")\n",
    "print(\"Team sanity check completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050fffc08866b10",
   "metadata": {},
   "source": [
    "## Workflow Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e521250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow design - prompts\n",
    "workflow_design_agenda = f\"\"\"\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt}\n",
    "\n",
    "Based on the project specification, selected tools, and implementation assignments, design a detailed step-by-step workflow for the transcriptomics analysis.\n",
    "\n",
    "The workflow should cover:\n",
    "1. Data preparation and quality control\n",
    "2. Statistical analysis (DESeq2 multi-factorial model)\n",
    "3. Functional annotation (pathway enrichment)\n",
    "4. Putative protein characterization\n",
    "5. Visualization and reporting\n",
    "\n",
    "Provide a clear, modular, and reproducible workflow with inputs, outputs, and quality checks for each step.\n",
    "\"\"\"\n",
    "\n",
    "workflow_design_questions = (\n",
    "    \"What is the complete step-by-step workflow for the analysis?\",\n",
    "    \"What are the inputs and outputs for each major step?\",\n",
    "    \"What quality control checks should be performed at each stage?\",\n",
    "    \"How will the different analysis components integrate together?\",\n",
    "    \"What are the key decision points and how should they be handled?\",\n",
    ")\n",
    "\n",
    "workflow_design_prior_summaries = load_summaries(\n",
    "    discussion_paths=[\n",
    "        discussions_phase_to_dir[\"team_selection\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"project_specification\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"tools_selection\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"implementation_agent_selection\"] / \"merged.json\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Number of prior summaries: {len(workflow_design_prior_summaries)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210bdc6d68bd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow design - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=principal_investigator,\n",
    "            agenda=workflow_design_agenda,\n",
    "            agenda_questions=workflow_design_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"workflow_design\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4534d4913ecf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow design - merge\n",
    "workflow_design_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"workflow_design\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(workflow_design_summaries)}\")\n",
    "\n",
    "workflow_design_merge_prompt = create_merge_prompt(\n",
    "    agenda=workflow_design_agenda,\n",
    "    agenda_questions=workflow_design_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=workflow_design_summaries,\n",
    "    agenda=workflow_design_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"workflow_design\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f0c589",
   "metadata": {},
   "source": [
    "## Writting Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# IMPLEMENTATION PHASES\n",
    "# ========================================\n",
    "\n",
    "# DESeq2 Statistical Analysis - prompts\n",
    "deseq2_analysis_agenda = f\"\"\"\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt}\n",
    "\n",
    "You are the Bioinformatics Statistician. Based on the workflow design, write a COMPLETE R script that implements the statistical analysis pipeline.\n",
    "\n",
    "The script must:\n",
    "1. Load count matrix (experimental_data/A2_count_matrix.txt) and sample metadata\n",
    "2. Create DESeq2 object with multi-factorial design: ~ genotype + treatment + genotype:treatment\n",
    "3. Filter low-count genes (‚â•10 counts in ‚â•3 samples)\n",
    "4. Run DESeq2 normalization and analysis\n",
    "5. Define contrasts to isolate resistance-specific effects\n",
    "6. Extract significant genes (FDR < 0.05, |log2FC| > 1.5)\n",
    "7. Perform diagnostic checks\n",
    "8. Export results to CSV files\n",
    "9. Include clear comments\n",
    "\n",
    "Write the complete R script now.\n",
    "\"\"\"\n",
    "\n",
    "deseq2_analysis_prior_summaries = load_summaries(\n",
    "    discussion_paths=[\n",
    "        discussions_phase_to_dir[\"workflow_design\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"tools_selection\"] / \"merged.json\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Number of prior summaries: {len(deseq2_analysis_prior_summaries)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c45cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESeq2 Statistical Analysis - implementation\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=team_members[1],  # Bioinformatics Statistician\n",
    "            summaries=deseq2_analysis_prior_summaries,\n",
    "            agenda=deseq2_analysis_agenda,\n",
    "            save_dir=discussions_phase_to_dir[\"deseq2_analysis\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CONSISTENT_TEMPERATURE,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e97114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESeq2 Statistical Analysis - merge\n",
    "deseq2_analysis_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"deseq2_analysis\"].glob(\"discussion_*.json\"))\n",
    ")\n",
    "print(f\"Number of summaries: {len(deseq2_analysis_summaries)}\")\n",
    "\n",
    "deseq2_analysis_merge_prompt = create_merge_prompt(agenda=deseq2_analysis_agenda)\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=team_members[1],  # Bioinformatics Statistician\n",
    "    summaries=deseq2_analysis_summaries,\n",
    "    agenda=deseq2_analysis_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"deseq2_analysis\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b2c7839b930aa",
   "metadata": {},
   "source": [
    "## Virtual Lab Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3a3d37081ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 26})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bebeb39ba3c3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_dir = Path(\"figures/virtual_lab_analysis\")\n",
    "figure_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "phase_to_agent_to_word_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577d08c72a2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words that the human user wrote\n",
    "phase_to_human_words = {\n",
    "    \"team_selection\": [\n",
    "        background_prompt,\n",
    "        principal_investigator.prompt,\n",
    "        scientific_critic.prompt,\n",
    "        team_selection_agenda.replace(f\"{background_prompt} \", \"\"),\n",
    "    ],\n",
    "    \"project_specification\": [\n",
    "        project_specification_agenda.replace(f\"{background_prompt} \", \"\"),\n",
    "        *project_specification_questions,\n",
    "        nanobody_prompt,\n",
    "    ],\n",
    "    \"tools_selection\": [\n",
    "        tools_selection_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        *tools_selection_questions,\n",
    "    ],\n",
    "    \"implementation_agent_selection\": [\n",
    "        implementation_agent_selection_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        *implementation_agent_selection_questions,\n",
    "    ],\n",
    "    \"esm\": [\n",
    "        esm_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        improve_esm_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "    ],\n",
    "    \"alphafold\": [\n",
    "        alphafold_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        improve_alphafold_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "    ],\n",
    "    \"rosetta\": [\n",
    "        rosetta_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        improve_rosetta_xml_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "        improve_rosetta_python_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "    ],\n",
    "    \"workflow_design\": [\n",
    "        workflow_design_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        *workflow_design_questions,\n",
    "    ],\n",
    "}\n",
    "\n",
    "for phase, human_words in phase_to_human_words.items():\n",
    "    phase_to_agent_to_word_count[phase] = {\"Human Researcher\": len(\" \".join(human_words).split())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b622f7378bd3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words that the LLM agents wrote\n",
    "for phase_name in [\"team_selection\", \"project_specification\", \"tools_selection\",\n",
    "                   \"implementation_agent_selection\", \"esm\", \"alphafold\", \"rosetta\", \"workflow_design\"]:\n",
    "    phase_dir = discussions_phase_to_dir[phase_name]\n",
    "\n",
    "    print(f\"Phase: {phase_name}\")\n",
    "\n",
    "    # Load the text written by each agent\n",
    "    agent_to_text = {}\n",
    "    for path in phase_dir.glob(\"*.json\"):\n",
    "        with open(path) as f:\n",
    "            discussion = json.load(f)\n",
    "\n",
    "        for message in discussion:\n",
    "            agent_to_text.setdefault(message[\"agent\"], []).append(message[\"message\"])\n",
    "\n",
    "    # Count the number of words written by each agent\n",
    "    for agent, text in agent_to_text.items():\n",
    "        if agent == \"User\":\n",
    "            continue\n",
    "\n",
    "        agent_to_text[agent] = \" \".join(text)\n",
    "        word_count = len(agent_to_text[agent].split())\n",
    "        phase_to_agent_to_word_count[phase_name][agent] = word_count\n",
    "\n",
    "# Print words by phase\n",
    "for phase in phase_to_agent_to_word_count:\n",
    "    print(f\"Phase: {phase}\")\n",
    "    for agent, word_count in phase_to_agent_to_word_count[phase].items():\n",
    "        print(f\"Number of words written by {agent}: {word_count:,}\")\n",
    "    print()\n",
    "\n",
    "# Sum word counts across phases\n",
    "agent_to_word_count = {}\n",
    "for phase in phase_to_agent_to_word_count:\n",
    "    for agent, word_count in phase_to_agent_to_word_count[phase].items():\n",
    "        agent_to_word_count[agent] = agent_to_word_count.get(agent, 0) + word_count\n",
    "\n",
    "# Total number of words written by each LLM agent\n",
    "for agent, word_count in agent_to_word_count.items():\n",
    "    print(f\"Total number of words written by {agent}: {word_count:,}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Total number of words written by all LLM agents\n",
    "total_human_words = sum(\n",
    "    phase_to_agent_to_word_count[phase][\"Human Researcher\"] for phase in phase_to_agent_to_word_count)\n",
    "total_agent_words = sum(word_count for agent, word_count in agent_to_word_count.items() if agent != \"Human Researcher\")\n",
    "\n",
    "print(f\"Total number of words written by Human Researcher: {total_human_words:,}\")\n",
    "print(f\"Total number of words written by all LLM agents: {total_agent_words:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd0609f9e7274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_to_color = {\n",
    "    agent: sns.color_palette(\"tab10\", n_colors=len(agent_to_word_count))[i]\n",
    "    for i, agent in enumerate(agent_to_word_count)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00e6cdaa1a1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "ax.pie(\n",
    "    agent_to_word_count.values(),\n",
    "    labels=agent_to_word_count.keys(),\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=[agent_to_color[agent] for agent in agent_to_word_count],\n",
    ")\n",
    "ax.set_title(f\"Words written\")\n",
    "plt.savefig(figure_dir / \"total_words_written.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465196358c50d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for phase in phase_to_agent_to_word_count:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    ax.pie(\n",
    "        phase_to_agent_to_word_count[phase].values(),\n",
    "        labels=phase_to_agent_to_word_count[phase].keys(),\n",
    "        autopct=\"%1.1f%%\",\n",
    "        colors=[agent_to_color[agent] for agent in phase_to_agent_to_word_count[phase]],\n",
    "    )\n",
    "    ax.set_title(f\"Words written in {phase.replace('_', ' ')}\")\n",
    "    plt.savefig(figure_dir / f\"{phase}_words_written.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed39621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01ffda913de4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
