{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import concurrent.futures\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from virtual_lab.constants import CONSISTENT_TEMPERATURE, CREATIVE_TEMPERATURE\n",
    "from virtual_lab.prompts import (\n",
    "    CODING_RULES,\n",
    "    REWRITE_PROMPT,\n",
    "    create_merge_prompt\n",
    ")\n",
    "from virtual_lab.run_meeting import run_meeting\n",
    "from virtual_lab.utils import load_summaries\n",
    "\n",
    "from transcriptomics_constants import (\n",
    "    background_prompt,\n",
    "    experimental_results_prompt,\n",
    "    num_iterations,\n",
    "    num_rounds,\n",
    "    discussions_phase_to_dir,\n",
    "    principal_investigator,\n",
    "    team_members,\n",
    "    scientific_critic,\n",
    "    statistician,\n",
    "    parasitologist,\n",
    "    computational_biologist,\n",
    "    software_developer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b8b27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API klíč načten: True\n",
      "Začátek klíče: sk-proj- ... konec: dowA\n",
      "SyncPage[Model](data=[Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-5-search-api-2025-10-14', created=1760043960, object='model', owned_by='system'), Model(id='gpt-realtime-mini', created=1759517133, object='model', owned_by='system'), Model(id='gpt-realtime-mini-2025-10-06', created=1759517175, object='model', owned_by='system'), Model(id='sora-2', created=1759708615, object='model', owned_by='system'), Model(id='sora-2-pro', created=1759708663, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='o1-mini-2024-09-12', created=1725648979, object='model', owned_by='system'), Model(id='o1-mini', created=1725649008, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system'), Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'), Model(id='o1-2024-12-17', created=1734326976, object='model', owned_by='system'), Model(id='o1', created=1734375816, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'), Model(id='o3-mini', created=1737146383, object='model', owned_by='system'), Model(id='o3-mini-2025-01-31', created=1738010200, object='model', owned_by='system'), Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'), Model(id='gpt-4o-search-preview-2025-03-11', created=1741388170, object='model', owned_by='system'), Model(id='gpt-4o-search-preview', created=1741388720, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview-2025-03-11', created=1741390858, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview', created=1741391161, object='model', owned_by='system'), Model(id='gpt-4o-transcribe', created=1742068463, object='model', owned_by='system'), Model(id='gpt-4o-mini-transcribe', created=1742068596, object='model', owned_by='system'), Model(id='o1-pro-2025-03-19', created=1742251504, object='model', owned_by='system'), Model(id='o1-pro', created=1742251791, object='model', owned_by='system'), Model(id='gpt-4o-mini-tts', created=1742403959, object='model', owned_by='system'), Model(id='o3-2025-04-16', created=1744133301, object='model', owned_by='system'), Model(id='o4-mini-2025-04-16', created=1744133506, object='model', owned_by='system'), Model(id='o3', created=1744225308, object='model', owned_by='system'), Model(id='o4-mini', created=1744225351, object='model', owned_by='system'), Model(id='gpt-4.1-2025-04-14', created=1744315746, object='model', owned_by='system'), Model(id='gpt-4.1', created=1744316542, object='model', owned_by='system'), Model(id='gpt-4.1-mini-2025-04-14', created=1744317547, object='model', owned_by='system'), Model(id='gpt-4.1-mini', created=1744318173, object='model', owned_by='system'), Model(id='gpt-4.1-nano-2025-04-14', created=1744321025, object='model', owned_by='system'), Model(id='gpt-4.1-nano', created=1744321707, object='model', owned_by='system'), Model(id='gpt-image-1', created=1745517030, object='model', owned_by='system'), Model(id='codex-mini-latest', created=1746673257, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2025-06-03', created=1748907838, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2025-06-03', created=1748908498, object='model', owned_by='system'), Model(id='o4-mini-deep-research', created=1749685485, object='model', owned_by='system'), Model(id='gpt-4o-transcribe-diarize', created=1750798887, object='model', owned_by='system'), Model(id='o4-mini-deep-research-2025-06-26', created=1750866121, object='model', owned_by='system'), Model(id='gpt-5-chat-latest', created=1754073306, object='model', owned_by='system'), Model(id='gpt-5-2025-08-07', created=1754075360, object='model', owned_by='system'), Model(id='gpt-5', created=1754425777, object='model', owned_by='system'), Model(id='gpt-5-mini-2025-08-07', created=1754425867, object='model', owned_by='system'), Model(id='gpt-5-mini', created=1754425928, object='model', owned_by='system'), Model(id='gpt-5-nano-2025-08-07', created=1754426303, object='model', owned_by='system'), Model(id='gpt-5-nano', created=1754426384, object='model', owned_by='system'), Model(id='gpt-audio-2025-08-28', created=1756256146, object='model', owned_by='system'), Model(id='gpt-realtime', created=1756271701, object='model', owned_by='system'), Model(id='gpt-realtime-2025-08-28', created=1756271773, object='model', owned_by='system'), Model(id='gpt-audio', created=1756339249, object='model', owned_by='system'), Model(id='gpt-5-codex', created=1757527818, object='model', owned_by='system'), Model(id='gpt-image-1-mini', created=1758845821, object='model', owned_by='system'), Model(id='gpt-5-pro-2025-10-06', created=1759469707, object='model', owned_by='system'), Model(id='gpt-5-pro', created=1759469822, object='model', owned_by='system'), Model(id='gpt-audio-mini', created=1759512027, object='model', owned_by='system'), Model(id='gpt-audio-mini-2025-10-06', created=1759512137, object='model', owned_by='system'), Model(id='gpt-5-search-api', created=1759514629, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal')], object='list')\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# testovací buňka moje\n",
    "\n",
    "print(\"API klíč načten:\", os.getenv(\"OPENAI_API_KEY\") is not None)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"Začátek klíče:\", api_key[:8], \"... konec:\", api_key[-4:])\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(client.models.list())\n",
    "\n",
    "print(openai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9259ddc2710488f",
   "metadata": {},
   "source": [
    "## Team selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47749ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team selection - prompts, pozor, když si jednou vyberu tým, už to znova nespouštím a nechám si ty konverzace v diskuzi\n",
    "team_selection_agenda = f\"\"\"\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt}\n",
    "\n",
    "You need to select a team of four scientists to help you with this transcriptomics project. The team should deal with these analytical challenges:\n",
    "\n",
    "- Multi-factorial statistical modeling to separate resistance from confounding factors\n",
    "- RNA-seq analysis and differential expression (DESeq2, edgeR)\n",
    "- Biological interpretation in the context of Giardia intestinalis biology and protozoan drug resistance\n",
    "- Implementation (R/Bioconductor, Python)\n",
    "- Functional annotation and characterization of putative/hypothetical proteins\n",
    "\n",
    "NOTE: Giardia intestinalis is a unique protozoan parasite with unusual biology. Understanding gene expression changes requires expertise in parasite physiology and drug resistance mechanisms.\n",
    "\n",
    "IMPORTANT: Many Giardia genes are annotated as \"putative protein\" or \"hypothetical protein\". The team needs expertise in:\n",
    "- Protein function prediction (sequence homology, domain analysis, structural prediction)\n",
    "- Comparative genomics to infer function from related organisms\n",
    "- Literature mining and database searches to assign putative functions\n",
    "\n",
    "Please select the team members in the following format. You should NOT include yourself (Principal Investigator) in the list. Write the team as a Python list of Agent objects with \"model=model\" as the last parameter.\n",
    "\n",
    "Agent(\n",
    "    title=\"Principal Investigator\",\n",
    "    expertise=\"transcriptomics, RNA-seq analysis, microbial drug resistance, experimental design\",\n",
    "    goal=\"identify molecular mechanisms of metronidazole resistance in Giardia intestinalis\",\n",
    "    role=\"lead a team of experts to properly re-analyze the RNA-seq data and identify validated candidate resistance genes\",\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "Principal Investigator, please provide your response.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50722e4dadc135d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team selection - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=principal_investigator,\n",
    "            agenda=team_selection_agenda,\n",
    "            save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c023cebeaaf883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team selection - merge\n",
    "team_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"team_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(team_selection_summaries)}\")\n",
    "\n",
    "team_selection_merge_prompt = create_merge_prompt(agenda=team_selection_agenda)\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=team_selection_summaries,\n",
    "    agenda=team_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"team_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804141d0b26537",
   "metadata": {},
   "source": [
    "## Projects specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df84a9e45d31bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_specification_agenda = f\"\"\"\n",
    "\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt} \n",
    "Design a transcriptomic analysis plan to identify genes specifically linked to metronidazole resistance in the BER line of Giardia intestinalis. Clearly distinguish resistance-specific effects from general drug responses and baseline strain differences. Propose a statistical model (e.g. with interaction terms) to detect these effects. Prioritize candidate resistance genes for validation and link them to biological functions using functional annotation tools. Include an approach for analyzing uncharacterized (putative) proteins.\"\"\"\n",
    "\n",
    "project_specification_questions = (\n",
    "    \"What is the most effective approach to identify genes linked to metronidazole resistance in *Giardia intestinalis*?\",\n",
    "    \"How can resistance-specific expression be separated from general drug response and baseline differences between strains?\",\n",
    "    \"Is a simple comparison sufficient, or is a complex statistical model needed? Why?\",\n",
    "    \"How should candidate genes be functionally annotated and connected to biological pathways?\",\n",
    "    \"What strategy can identify and characterize putative (unannotated) proteins among the candidate genes?\",\n",
    "    \"Are any additional files, metadata, or annotations needed to perform the analysis effectively?\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff509ba8824b8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rounds (+ Final Round):   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Team:  67%|██████▋   | 4/6 [01:17<00:38, 19.35s/it]\n",
      "Rounds (+ Final Round):   0%|          | 0/4 [01:17<?, ?it/s]\n",
      "Team:  83%|████████▎ | 5/6 [01:17<00:15, 15.45s/it]\n",
      "Rounds (+ Final Round):   0%|          | 0/4 [01:17<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Team: 100%|██████████| 6/6 [01:41<00:00, 16.88s/it]\n",
      "\n",
      "\n",
      "\n",
      "Team:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team:  83%|████████▎ | 5/6 [01:46<00:21, 21.33s/it]\n",
      "Rounds (+ Final Round):   0%|          | 0/4 [01:46<?, ?it/s]\n",
      "Team:   0%|          | 0/6 [00:07<?, ?it/s]\n",
      "Rounds (+ Final Round):  25%|██▌       | 1/4 [01:49<05:27, 109.08s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team: 100%|██████████| 6/6 [02:02<00:00, 20.35s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team: 100%|██████████| 6/6 [01:30<00:00, 15.07s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Team:  67%|██████▋   | 4/6 [00:52<00:26, 13.23s/it]\n",
      "Rounds (+ Final Round):  50%|█████     | 2/4 [04:25<04:25, 132.70s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Project specification - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"team\",\n",
    "            team_lead=principal_investigator,\n",
    "            team_members=team_members,\n",
    "            agenda=project_specification_agenda,\n",
    "            agenda_questions=project_specification_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            num_rounds=num_rounds,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e0cfa85f2176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project specification - merge\n",
    "project_specification_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"project_specification\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(project_specification_summaries)}\")\n",
    "\n",
    "project_specification_merge_prompt = create_merge_prompt(\n",
    "    agenda=project_specification_agenda,\n",
    "    agenda_questions=project_specification_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=project_specification_summaries,\n",
    "    agenda=project_specification_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"project_specification\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    num_rounds=num_rounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5307d354d28011",
   "metadata": {},
   "source": [
    "## Tools Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools selection - prompts\n",
    "tools_selection_agenda = f\"\"\"\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt}\n",
    "\n",
    "Based on the project specification discussion, select the specific computational and bioinformatics tools needed to implement the transcriptomics analysis plan.\n",
    "\n",
    "IMPORTANT: Consider both established tools AND recent innovations in the field. The analysis should leverage:\n",
    "- Modern statistical approaches for multi-factorial RNA-seq analysis\n",
    "- State-of-the-art methods for protein function prediction\n",
    "- Recent advances in AI/ML for biological sequence analysis\n",
    "- Novel approaches for analyzing non-model organisms like Giardia\n",
    "\n",
    "Please list and justify your tool choices for:\n",
    "- Statistical analysis and differential expression\n",
    "- Functional annotation and pathway enrichment\n",
    "- Protein function prediction for putative/hypothetical proteins (consider recent advances in structure and function prediction)\n",
    "- Data processing and visualization\n",
    "- Giardia-specific or protozoan-specific resources\n",
    "\n",
    "For each tool, explain:\n",
    "1. How it will be used in the workflow\n",
    "2. Why it's appropriate for this project\n",
    "3. Whether there are newer alternatives worth considering\n",
    "\n",
    "Feel free to suggest cutting-edge tools or innovative approaches that could enhance the analysis beyond traditional methods.\n",
    "\"\"\"\n",
    "\n",
    "tools_selection_questions = (\n",
    "    \"What computational tools should be used for the RNA-seq analysis (include both established and innovative tools)?\",\n",
    "    \"For each tool, how will it be specifically applied to identify metronidazole resistance mechanisms?\",\n",
    "    \"Which pathway databases and functional annotation resources are most appropriate for Giardia?\",\n",
    "    \"What modern approaches (including AI-powered tools) should be used for characterizing putative proteins?\",\n",
    "    \"Are there any recent advances in protozoan genomics tools that could benefit this analysis?\",\n",
    ")\n",
    "\n",
    "tools_selection_prior_summaries = load_summaries(\n",
    "    discussion_paths=[discussions_phase_to_dir[\"project_specification\"] / \"merged.json\"])\n",
    "print(f\"Number of prior summaries: {len(tools_selection_prior_summaries)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95de22d2f1d277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools selection - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"team\",\n",
    "            team_lead=principal_investigator,\n",
    "            team_members=team_members,\n",
    "            summaries=tools_selection_prior_summaries,\n",
    "            agenda=tools_selection_agenda,\n",
    "            agenda_questions=tools_selection_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"tools_selection\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            num_rounds=num_rounds,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580378a119b0cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools selection - merge\n",
    "tools_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"tools_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(tools_selection_summaries)}\")\n",
    "\n",
    "tools_selection_merge_prompt = create_merge_prompt(\n",
    "    agenda=tools_selection_agenda,\n",
    "    agenda_questions=tools_selection_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=tools_selection_summaries,\n",
    "    agenda=tools_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"tools_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    num_rounds=num_rounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3777aacd05e6e17",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation agent selection - prompts\n",
    "implementation_agent_selection_agenda = f\"\"\"\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt}\n",
    "\n",
    "Based on the project specification and selected tools, your team needs to implement the transcriptomics analysis pipeline.\n",
    "\n",
    "The analysis requires implementation of several major components:\n",
    "\n",
    "1. Statistical analysis pipeline (DESeq2 multi-factorial model with interaction terms)\n",
    "2. Functional annotation pipeline (ClusterProfiler, ReactomePA, pathway enrichment)\n",
    "3. Putative protein characterization (AlphaFold, RoseTTAFold, domain analysis)\n",
    "4. Data visualization and reporting (ggplot2, Plotly, comprehensive plots)\n",
    "\n",
    "Please discuss and select which team member(s) will implement each component. Team members may implement multiple components, and components may be implemented collaboratively.\n",
    "\n",
    "Consider each team member's expertise when making assignments.\n",
    "\"\"\"\n",
    "\n",
    "implementation_agent_selection_questions = (\n",
    "    \"Which team member(s) will implement the statistical analysis pipeline (DESeq2, multi-factorial model)?\",\n",
    "    \"Which team member(s) will implement the functional annotation pipeline (ClusterProfiler, ReactomePA)?\",\n",
    "    \"Which team member(s) will implement the putative protein characterization component (AlphaFold, domain analysis)?\",\n",
    "    \"Which team member(s) will implement data visualization and reporting?\",\n",
    ")\n",
    "\n",
    "implementation_agent_selection_prior_summaries = load_summaries(\n",
    "    discussion_paths=[\n",
    "        discussions_phase_to_dir[\"team_selection\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"project_specification\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"tools_selection\"] / \"merged.json\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Number of prior summaries: {len(implementation_agent_selection_prior_summaries)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c7f17e1853145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=principal_investigator,\n",
    "            summaries=implementation_agent_selection_prior_summaries,\n",
    "            agenda=implementation_agent_selection_agenda,\n",
    "            agenda_questions=implementation_agent_selection_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"implementation_agent_selection\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741ab035e21003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation - merge\n",
    "implementation_agent_selection_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"implementation_agent_selection\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(implementation_agent_selection_summaries)}\")\n",
    "\n",
    "implementation_agent_selection_merge_prompt = create_merge_prompt(\n",
    "    agenda=implementation_agent_selection_agenda,\n",
    "    agenda_questions=implementation_agent_selection_questions\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=implementation_agent_selection_summaries,\n",
    "    agenda=implementation_agent_selection_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"implementation_agent_selection\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050fffc08866b10",
   "metadata": {},
   "source": [
    "## Workflow Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e521250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow design - prompts\n",
    "workflow_design_agenda = f\"\"\"\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt}\n",
    "\n",
    "Based on the project specification, selected tools, and implementation assignments, design a detailed step-by-step workflow for the transcriptomics analysis.\n",
    "\n",
    "The workflow should cover:\n",
    "1. Data preparation and quality control\n",
    "2. Statistical analysis (DESeq2 multi-factorial model)\n",
    "3. Functional annotation (pathway enrichment)\n",
    "4. Putative protein characterization\n",
    "5. Visualization and reporting\n",
    "\n",
    "Provide a clear, modular, and reproducible workflow with inputs, outputs, and quality checks for each step.\n",
    "\"\"\"\n",
    "\n",
    "workflow_design_questions = (\n",
    "    \"What is the complete step-by-step workflow for the analysis?\",\n",
    "    \"What are the inputs and outputs for each major step?\",\n",
    "    \"What quality control checks should be performed at each stage?\",\n",
    "    \"How will the different analysis components integrate together?\",\n",
    "    \"What are the key decision points and how should they be handled?\",\n",
    ")\n",
    "\n",
    "workflow_design_prior_summaries = load_summaries(\n",
    "    discussion_paths=[\n",
    "        discussions_phase_to_dir[\"team_selection\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"project_specification\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"tools_selection\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"implementation_agent_selection\"] / \"merged.json\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Number of prior summaries: {len(workflow_design_prior_summaries)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210bdc6d68bd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow design - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=principal_investigator,\n",
    "            agenda=workflow_design_agenda,\n",
    "            agenda_questions=workflow_design_questions,\n",
    "            save_dir=discussions_phase_to_dir[\"workflow_design\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4534d4913ecf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow design - merge\n",
    "workflow_design_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"workflow_design\"].glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(workflow_design_summaries)}\")\n",
    "\n",
    "workflow_design_merge_prompt = create_merge_prompt(\n",
    "    agenda=workflow_design_agenda,\n",
    "    agenda_questions=workflow_design_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=principal_investigator,\n",
    "    summaries=workflow_design_summaries,\n",
    "    agenda=workflow_design_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"workflow_design\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f0c589",
   "metadata": {},
   "source": [
    "## Writting Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# IMPLEMENTATION PHASES\n",
    "# ========================================\n",
    "\n",
    "# DESeq2 Statistical Analysis - prompts\n",
    "deseq2_analysis_agenda = f\"\"\"\n",
    "{background_prompt}\n",
    "\n",
    "{experimental_results_prompt}\n",
    "\n",
    "You are the Bioinformatics Statistician. Based on the workflow design, write a COMPLETE R script that implements the statistical analysis pipeline.\n",
    "\n",
    "The script must:\n",
    "1. Load count matrix (experimental_data/A2_count_matrix.txt) and sample metadata\n",
    "2. Create DESeq2 object with multi-factorial design: ~ genotype + treatment + genotype:treatment\n",
    "3. Filter low-count genes (≥10 counts in ≥3 samples)\n",
    "4. Run DESeq2 normalization and analysis\n",
    "5. Define contrasts to isolate resistance-specific effects\n",
    "6. Extract significant genes (FDR < 0.05, |log2FC| > 1.5)\n",
    "7. Perform diagnostic checks\n",
    "8. Export results to CSV files\n",
    "9. Include clear comments\n",
    "\n",
    "Write the complete R script now.\n",
    "\"\"\"\n",
    "\n",
    "deseq2_analysis_prior_summaries = load_summaries(\n",
    "    discussion_paths=[\n",
    "        discussions_phase_to_dir[\"workflow_design\"] / \"merged.json\",\n",
    "        discussions_phase_to_dir[\"tools_selection\"] / \"merged.json\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Number of prior summaries: {len(deseq2_analysis_prior_summaries)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c45cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESeq2 Statistical Analysis - implementation\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=team_members[1],  # Bioinformatics Statistician\n",
    "            summaries=deseq2_analysis_prior_summaries,\n",
    "            agenda=deseq2_analysis_agenda,\n",
    "            save_dir=discussions_phase_to_dir[\"deseq2_analysis\"],\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CONSISTENT_TEMPERATURE,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e97114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESeq2 Statistical Analysis - merge\n",
    "deseq2_analysis_summaries = load_summaries(\n",
    "    discussion_paths=list(discussions_phase_to_dir[\"deseq2_analysis\"].glob(\"discussion_*.json\"))\n",
    ")\n",
    "print(f\"Number of summaries: {len(deseq2_analysis_summaries)}\")\n",
    "\n",
    "deseq2_analysis_merge_prompt = create_merge_prompt(agenda=deseq2_analysis_agenda)\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=team_members[1],  # Bioinformatics Statistician\n",
    "    summaries=deseq2_analysis_summaries,\n",
    "    agenda=deseq2_analysis_merge_prompt,\n",
    "    save_dir=discussions_phase_to_dir[\"deseq2_analysis\"],\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b2c7839b930aa",
   "metadata": {},
   "source": [
    "## Virtual Lab Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3a3d37081ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 26})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bebeb39ba3c3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_dir = Path(\"figures/virtual_lab_analysis\")\n",
    "figure_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "phase_to_agent_to_word_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577d08c72a2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words that the human user wrote\n",
    "phase_to_human_words = {\n",
    "    \"team_selection\": [\n",
    "        background_prompt,\n",
    "        principal_investigator.prompt,\n",
    "        scientific_critic.prompt,\n",
    "        team_selection_agenda.replace(f\"{background_prompt} \", \"\"),\n",
    "    ],\n",
    "    \"project_specification\": [\n",
    "        project_specification_agenda.replace(f\"{background_prompt} \", \"\"),\n",
    "        *project_specification_questions,\n",
    "        nanobody_prompt,\n",
    "    ],\n",
    "    \"tools_selection\": [\n",
    "        tools_selection_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        *tools_selection_questions,\n",
    "    ],\n",
    "    \"implementation_agent_selection\": [\n",
    "        implementation_agent_selection_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        *implementation_agent_selection_questions,\n",
    "    ],\n",
    "    \"esm\": [\n",
    "        esm_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        improve_esm_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "    ],\n",
    "    \"alphafold\": [\n",
    "        alphafold_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        improve_alphafold_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "    ],\n",
    "    \"rosetta\": [\n",
    "        rosetta_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        improve_rosetta_xml_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "        improve_rosetta_python_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "    ],\n",
    "    \"workflow_design\": [\n",
    "        workflow_design_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        *workflow_design_questions,\n",
    "    ],\n",
    "}\n",
    "\n",
    "for phase, human_words in phase_to_human_words.items():\n",
    "    phase_to_agent_to_word_count[phase] = {\"Human Researcher\": len(\" \".join(human_words).split())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b622f7378bd3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words that the LLM agents wrote\n",
    "for phase_name in [\"team_selection\", \"project_specification\", \"tools_selection\",\n",
    "                   \"implementation_agent_selection\", \"esm\", \"alphafold\", \"rosetta\", \"workflow_design\"]:\n",
    "    phase_dir = discussions_phase_to_dir[phase_name]\n",
    "\n",
    "    print(f\"Phase: {phase_name}\")\n",
    "\n",
    "    # Load the text written by each agent\n",
    "    agent_to_text = {}\n",
    "    for path in phase_dir.glob(\"*.json\"):\n",
    "        with open(path) as f:\n",
    "            discussion = json.load(f)\n",
    "\n",
    "        for message in discussion:\n",
    "            agent_to_text.setdefault(message[\"agent\"], []).append(message[\"message\"])\n",
    "\n",
    "    # Count the number of words written by each agent\n",
    "    for agent, text in agent_to_text.items():\n",
    "        if agent == \"User\":\n",
    "            continue\n",
    "\n",
    "        agent_to_text[agent] = \" \".join(text)\n",
    "        word_count = len(agent_to_text[agent].split())\n",
    "        phase_to_agent_to_word_count[phase_name][agent] = word_count\n",
    "\n",
    "# Print words by phase\n",
    "for phase in phase_to_agent_to_word_count:\n",
    "    print(f\"Phase: {phase}\")\n",
    "    for agent, word_count in phase_to_agent_to_word_count[phase].items():\n",
    "        print(f\"Number of words written by {agent}: {word_count:,}\")\n",
    "    print()\n",
    "\n",
    "# Sum word counts across phases\n",
    "agent_to_word_count = {}\n",
    "for phase in phase_to_agent_to_word_count:\n",
    "    for agent, word_count in phase_to_agent_to_word_count[phase].items():\n",
    "        agent_to_word_count[agent] = agent_to_word_count.get(agent, 0) + word_count\n",
    "\n",
    "# Total number of words written by each LLM agent\n",
    "for agent, word_count in agent_to_word_count.items():\n",
    "    print(f\"Total number of words written by {agent}: {word_count:,}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Total number of words written by all LLM agents\n",
    "total_human_words = sum(\n",
    "    phase_to_agent_to_word_count[phase][\"Human Researcher\"] for phase in phase_to_agent_to_word_count)\n",
    "total_agent_words = sum(word_count for agent, word_count in agent_to_word_count.items() if agent != \"Human Researcher\")\n",
    "\n",
    "print(f\"Total number of words written by Human Researcher: {total_human_words:,}\")\n",
    "print(f\"Total number of words written by all LLM agents: {total_agent_words:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd0609f9e7274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_to_color = {\n",
    "    agent: sns.color_palette(\"tab10\", n_colors=len(agent_to_word_count))[i]\n",
    "    for i, agent in enumerate(agent_to_word_count)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00e6cdaa1a1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "ax.pie(\n",
    "    agent_to_word_count.values(),\n",
    "    labels=agent_to_word_count.keys(),\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=[agent_to_color[agent] for agent in agent_to_word_count],\n",
    ")\n",
    "ax.set_title(f\"Words written\")\n",
    "plt.savefig(figure_dir / \"total_words_written.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465196358c50d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for phase in phase_to_agent_to_word_count:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    ax.pie(\n",
    "        phase_to_agent_to_word_count[phase].values(),\n",
    "        labels=phase_to_agent_to_word_count[phase].keys(),\n",
    "        autopct=\"%1.1f%%\",\n",
    "        colors=[agent_to_color[agent] for agent in phase_to_agent_to_word_count[phase]],\n",
    "    )\n",
    "    ax.set_title(f\"Words written in {phase.replace('_', ' ')}\")\n",
    "    plt.savefig(figure_dir / f\"{phase}_words_written.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed39621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01ffda913de4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
